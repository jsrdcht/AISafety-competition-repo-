{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from albumentations import (\n",
    "    IAAPerspective, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, PiecewiseAffine,\n",
    "    Sharpen, Emboss, RandomBrightnessContrast, OneOf, Compose, Cutout, CoarseDropout, ShiftScaleRotate,\n",
    ")\n",
    "import torchvision\n",
    "from tqdm.std import trange\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.chdir(\"/home/ct/aaai2021/\")   #修改当前工作目录"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# gen_dataset.py"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:18<00:00, 550.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 3) uint8 (10000, 10) float64\n"
     ]
    }
   ],
   "source": [
    "def get_train_transforms():\n",
    "    return Compose(\n",
    "        [\n",
    "            Transpose(p=0.25),\n",
    "            GaussNoise(p=0.75),\n",
    "            OneOf([\n",
    "                # 模糊相关操作\n",
    "                MotionBlur(p=.75),\n",
    "                MedianBlur(blur_limit=3, p=0.5),\n",
    "                Blur(blur_limit=3, p=0.75),\n",
    "            ], p=0.25),\n",
    "            ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=0.25),\n",
    "            OneOf([\n",
    "                # 畸变相关操作\n",
    "                OpticalDistortion(p=0.75),\n",
    "                GridDistortion(p=0.25),\n",
    "                PiecewiseAffine(p=0.75),\n",
    "            ], p=0.25),\n",
    "            OneOf([\n",
    "                # 锐化、浮雕等操作\n",
    "                CLAHE(clip_limit=2),\n",
    "                Sharpen(),\n",
    "                Emboss(),\n",
    "                RandomBrightnessContrast(),\n",
    "            ], p=0.25),\n",
    "            #\n",
    "            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "            OneOf(\n",
    "                [\n",
    "                    CoarseDropout(max_holes=4,\n",
    "                                  max_height=4,\n",
    "                                  max_width=4,\n",
    "                                  p=0.5),\n",
    "                    Cutout(\n",
    "                        num_holes=4,\n",
    "                        max_h_size=4,\n",
    "                        max_w_size=4,\n",
    "                        p=0.5,)],\n",
    "                p=0.5)\n",
    "        ]\n",
    "    )\n",
    "'''\n",
    "image = Image.fromarray(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
    "img = cv2.cvtColor(numpy.asarray(image),cv2.COLOR_RGB2BGR)\n",
    "'''\n",
    "#label-smoothing\n",
    "confidence = 0.8\n",
    "smoothing = 0.2\n",
    "cls= 10\n",
    "dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True)\n",
    "images = []\n",
    "soft_labels = []\n",
    "transform=get_train_transforms()\n",
    "cnt=-1\n",
    "for image, label in tqdm(dataset):\n",
    "    image = np.array(image)\n",
    "    #images.append(image)\n",
    "    soft_label = np.zeros(10)\n",
    "    soft_label[label] += confidence # an unnormalized soft label vector\n",
    "    for inx in range(soft_label.shape[0]):\n",
    "        if inx!=label:\n",
    "            soft_label[inx]=smoothing / (cls - 1)\n",
    "    #soft_labels.append(soft_label)\n",
    "    #-----------image aug------------\n",
    "    #cnt+=1\n",
    "    #if cnt<10000:\n",
    "    #数据增强\n",
    "    for _ in range(1):\n",
    "        img=transform(image=image)['image']\n",
    "        images.append(img)\n",
    "        soft_labels.append(soft_label)\n",
    "        #break\n",
    "    #else:\n",
    "    #    continue\n",
    "#\n",
    "images = np.array(images)\n",
    "soft_labels = np.array(soft_labels)\n",
    "print(images.shape, images.dtype, soft_labels.shape, soft_labels.dtype)\n",
    "np.save('./data/DLLXW_test_images_1w.npy', images)\n",
    "np.save('./data/DLLXW_test_labels_1w.npy', soft_labels)\n",
    "\n",
    "# img=images[10]\n",
    "# img_aug=transform(image=img)['image']\n",
    "# #demo=Image.fromarray(images[0])\n",
    "# img=cv2.cvtColor(np.asarray(img),cv2.COLOR_RGB2BGR)\n",
    "# cv2.imwrite('img.jpg',img)\n",
    "# img_aug=cv2.cvtColor(np.asarray(img_aug),cv2.COLOR_RGB2BGR)\n",
    "# cv2.imwrite('img_aug.jpg',img_aug)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "markdown",
   "source": "# 添加40000个train 里的样本 其它保持同步",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": "# cls= 10\n# dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)\n# train_images = []\n# train_labels = []\n# transform=get_train_transforms()\n# cnt=-1\n# for image, label in tqdm(dataset):\n#     image = np.array(image)\n#     #images.append(image)\n#     soft_label = np.zeros(10)\n#     soft_label[label] += confidence # an unnormalized soft label vector\n#     for inx in range(soft_label.shape[0]):\n#         if inx!=label:\n#             soft_label[inx]=smoothing / (cls - 1)\n#     #soft_labels.append(soft_label)\n#     #-----------image aug------------\n#     #cnt+=1\n#     #if cnt<10000:\n#     #数据增强\n#     for _ in range(1):\n#         img=transform(image=image)['image']\n#         train_images.append(img)\n#         train_labels.append(soft_label)\n#         #break\n#     #else:\n#     #    continue\n# #\n# train_images = np.array(train_images)\n# train_labels = np.array(train_labels)\n# print(train_images.shape, train_images.dtype, train_labels.shape, train_labels.dtype)\n#\n# images = np.concatenate([images,train_images[0:40000]])\n# soft_labels = np.concatenate([soft_labels,train_labels[0:40000]])\n#\n# print(images.shape, images.dtype, soft_labels.shape, soft_labels.dtype)\n# np.save('./data/cifar_image_train.npy', images)\n# np.save('./data/cifar_label_train.npy', soft_labels)",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}